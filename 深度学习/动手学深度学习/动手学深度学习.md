## 环境准备
- `conda create --name d2l python=3.9 -y`
- `conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia`
- `python -m pip install d2l`
## 序言

### 训练过程

### 机器学习中的关键组件

- 可以用来学习的数据（data）
- 如何转换数据的模型（model）
- 一个目标函数（objective function），用来量化模型的有效性
- 调整模型参数以优化目标函数的算法（algorithm）
![](_attachments/Pasted%20image%2020230817204605.png)
### 数据
- 数据集包含若干样本
- 样本包含若干特征 

不是所有的特征都可以通过固定长度的向量表示，如文本数据。深度学习的一个主要优势是可以处理不同长度的数据。

**数据的要求** ：海量、正确的数据 

### 模型
#### 目标函数
目标函数（损失函数）用来度量模型的优劣程度。

损失函数不是越小越好。为了避免在训练集数据**过拟合**。要同时测试集数据的准确性。

#### 优化算法
用于最小化损失函数。

常见的优化算法：梯度下降。在每个步骤中，梯度下降法都会检查每个参数，看看如果仅对该参数进行少量变动，训练集损失会朝哪个方向移动。 然后，它在可以减少损失的方向上优化参数。

### 机器学习中的各种问题
#### 监督学习
![[Pasted image 20230817204616.png]]
##### 步骤
- 选择一个样本子集，为每个样本获取真实的标签。作为训练集
- 选择有监督的学习算法，使用训练集作为输入，输出一个已经完成学习的模型 
- 将没有见过的样本放入 已经完成学习的模型 中，使用模型的输出作为相应标签的预测。 
##### 回归
通常使用平方误差作为损失函数。
##### 分类
通常使用交叉熵作为损失函数。
##### 标记问题
文章或图片可能被打上多个标签
##### 搜索
对一组项目进行分类、排序。
##### 推荐系统
##### 序列学习
输入的样本时间如果有相互关系。如语音识别，主语谓语的标注和解析，文本到语音，机器翻译等。
#### 无监督学习
聚类、主成分分析、因果关系和概率图模型、生成对抗性网络
#### 与环境互动
前面的监督学习和非监督学习都是预先获取数据，然后启动模型，不再与环境交互。称为**离线学习**。
![[Pasted image 20230817204630.png]]

与环境互动几种可能：
- 环境是否重要？
- 环境是否要打败模型？
- 环境是否有助于我们建模
- 环境是否变化

#### 强化学习
![[Pasted image 20230817204638.png]]
agent在一系列的时间步骤上和环境交互。每个特定的时间点，agent从环境接受一些观察（observation），并且必须选择一个动作（action），然后通过某种机制将其传输回环境，最后agent从环境中获得奖励。此后新一轮循环开始。

当环境可被完全观察到时，强化学习称为马尔可夫决策过程。当状态不依赖之前的操作，称为 上下文赌博机。当没有状态，只有一组最初未知回报的可用动作时，这个问题是 多臂赌博机。

> - 线性和非线性处理单元的交替，通常称为*层*（layers）；
> - 使用链式规则（也称为*反向传播*（backpropagation））一次性调整网络中的全部参数。